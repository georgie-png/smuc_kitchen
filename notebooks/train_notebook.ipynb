{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T08:56:32.542212Z",
     "start_time": "2024-04-04T08:56:30.709005Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.optim as optimizers\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import SimpleMLP, MLPVariableLayers, SimplestMLP\n",
    "from data_loaders import KitchenDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526f8a9aa2057eff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T08:56:32.543108Z",
     "start_time": "2024-04-04T08:56:32.540223Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "data_path = '../data/Full-Data-80-20-split-6-kitchens-6000.json'\n",
    "    #['../data/test_data_6_kitchens_60.json', '../data/test_data_6_kitchens_80.json'] #'../data/Full-Data-80-20-split-6000.json'\n",
    "\n",
    "# setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "HIDDEN_LAYERS = 1\n",
    "HIDDEN_FEATURES = 512\n",
    "\n",
    "BATCH_SIZE = 1000\n",
    "NUM_EPOCHS = 5000\n",
    "LR = 0.0004\n",
    "WD = 0.0\n",
    "\n",
    "N_COMPONENTS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55c0ae3cee50b83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T08:56:33.030576Z",
     "start_time": "2024-04-04T08:56:32.544875Z"
    }
   },
   "outputs": [],
   "source": [
    "# get full dataset\n",
    "#kitchen_dataset = KitchenDataset(data_path)\n",
    "\n",
    "train_data = KitchenDataset(data_path, train='train', num_examples=2000)\n",
    "test_data = KitchenDataset(data_path, train='test')\n",
    "\n",
    "#kitchen_dataset = KitchenDatasetSVD(data_path, n_components=N_COMPONENTS)\n",
    "#train_data = KitchenDataset(data_path, train=True, num_examples=1024)\n",
    "#test_data = KitchenDataset(data_path, train=False, num_examples=4000)\n",
    "#num_kitchens = train_data.num_kitchens\n",
    "#num_items = train_data.num_items\n",
    "\n",
    "# split data into training and test data\n",
    "num_kitchens = train_data.num_kitchens\n",
    "num_items = train_data.num_items\n",
    "#train_data, test_data = torch.utils.data.random_split(kitchen_dataset, [500, 4500])\n",
    "num_training_examples = len(train_data)#int(0.8 * len(kitchen_dataset))\n",
    "num_test_examples = len(test_data)\n",
    "\n",
    "\n",
    "# setup data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b1c4610a8185ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T08:56:33.031563Z",
     "start_time": "2024-04-04T08:56:33.021477Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize model and optimizer\n",
    "data_max, data_min = train_data.get_max_min()\n",
    "#model = SimpleMLP(num_kitchens=num_kitchens,\n",
    "#                  num_items=num_items,\n",
    "#                  hidden_layers=HIDDEN_LAYERS, \n",
    "#                  hidden_features=HIDDEN_FEATURES,\n",
    "#                  data_max=data_max,\n",
    "#                  data_min=data_min,\n",
    "#                  n_components=N_COMPONENTS).to(device)\n",
    "\n",
    "model = SimplestMLP(num_kitchens=num_kitchens,\n",
    "                          num_items=num_items,\n",
    "                          hidden_features=[1024],\n",
    "                          data_max=data_max,\n",
    "                          data_min=data_min).to(device)\n",
    "\n",
    "#model = ExperimentalModel(num_kitchens=num_kitchens,\n",
    "#                          num_items=num_items,\n",
    "#                          hidden_layers=HIDDEN_LAYERS, \n",
    "#                          hidden_features=HIDDEN_FEATURES,\n",
    "#                          data_means=train_data.get_food_means()\n",
    "#                          ).to(device)\n",
    "optim = optimizers.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
    "criterion = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b45733fa15e2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T08:59:10.130090Z",
     "start_time": "2024-04-04T08:56:33.031719Z"
    }
   },
   "outputs": [],
   "source": [
    "# TRAIN CLASSIFIER\n",
    "print('=' * 32)\n",
    "print(f'Start training')\n",
    "print(f'Device: {device}')\n",
    "print(f'Number of epochs: {NUM_EPOCHS}')\n",
    "print('=' * 32)\n",
    "\n",
    "losses = []\n",
    "test_losses = []\n",
    "accuracies = []\n",
    "test_x = []\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# MAIN TRAINING LOOP\n",
    "# -----------------------------------------------------------------\n",
    "prog_bar = tqdm(range(NUM_EPOCHS))\n",
    "num_training_iterations = 0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # train one epoch\n",
    "    for _, (data, targets) in enumerate(iter(train_loader)):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        prediction = model(data)\n",
    "        loss = criterion(prediction, targets)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        num_training_iterations += 1\n",
    "    \n",
    "    # validation\n",
    "    test_loss = 0\n",
    "    test_predictions = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        # iterate through test set\n",
    "        for _, (data, targets) in enumerate(iter(test_loader)):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            prediction = model(data, center_data=True)\n",
    "            test_loss += criterion(prediction, targets, reduction='sum')\n",
    "            test_predictions.append(prediction)\n",
    "            true_labels.append(targets)\n",
    "        # average test loss\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_losses.append(test_loss)\n",
    "        test_x.append(num_training_iterations)\n",
    "        \n",
    "        # compute accuracy\n",
    "        true_test_labels = torch.argmax(torch.cat(true_labels).detach().cpu(), dim=1)\n",
    "        all_predictions = torch.argmax(torch.cat(test_predictions).detach().cpu(), dim=1)\n",
    "        accuracy = torch.sum(torch.where(all_predictions - true_test_labels == 0, 1, 0)) / len(test_data) * 100\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    prog_bar.update(1)\n",
    "\n",
    "prog_bar.close()    \n",
    "\n",
    "# plot summary\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "fig.suptitle('Training Summary')\n",
    "ax[0].plot(np.log(losses), label='Training Loss')\n",
    "ax[0].plot(test_x, np.log(test_losses), label='Test Loss')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel('Iterations')\n",
    "ax[0].set_ylabel('log loss')\n",
    "ax[0].set_title(f'Log loss over {NUM_EPOCHS} epochs')\n",
    "ax[1].plot(test_x, accuracies, label='Test Accuracy')\n",
    "ax[1].set_xlabel('Iterations')\n",
    "ax[1].set_ylabel('Accuracy %')\n",
    "ax[1].set_title(f'Final Accuracy: {accuracies[-1] :.2f}%')\n",
    "#ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a7a8525a130c28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T08:59:10.158141Z",
     "start_time": "2024-04-04T08:59:10.146058Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32095558b8a4c433",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T08:59:10.175542Z",
     "start_time": "2024-04-04T08:59:10.158828Z"
    }
   },
   "outputs": [],
   "source": [
    "len(train_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd42a3b6184fa05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T08:59:10.177853Z",
     "start_time": "2024-04-04T08:59:10.176320Z"
    }
   },
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
