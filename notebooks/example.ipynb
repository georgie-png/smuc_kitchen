{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T10:01:03.646173Z",
     "start_time": "2024-04-04T10:01:03.637936Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3192be647b929a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T10:01:03.646372Z",
     "start_time": "2024-04-04T10:01:03.640572Z"
    }
   },
   "outputs": [],
   "source": [
    "from training import train_model, continue_training, get_list_of_models\n",
    "from utils.get_device import get_device\n",
    "import utils.save_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb663d92d8da5248",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T10:01:03.657761Z",
     "start_time": "2024-04-04T10:01:03.644213Z"
    }
   },
   "outputs": [],
   "source": [
    "# fix random seeds\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# define path to dataset, can contain multiple files in the list\n",
    "data_path = ['../data/Full-Data-80-20-split-6-kitchens-6000.json']\n",
    "\n",
    "# get device\n",
    "device = get_device()\n",
    "\n",
    "# get list of available models to train\n",
    "print(get_list_of_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569fa11090fec235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T10:01:43.740676Z",
     "start_time": "2024-04-04T10:01:03.654233Z"
    }
   },
   "outputs": [],
   "source": [
    "# define hyperparameters for training\n",
    "NUM_EPOCHS = 600 # number of training epochs\n",
    "LR = 0.0002 # learning rate\n",
    "LAYERS = [512] # number of features in each layer of the network.\n",
    "\n",
    "# train model\n",
    "model, summary = train_model(\n",
    "    data_paths=data_path,\n",
    "    lr=LR,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    layers=LAYERS,\n",
    "    model_type='MLP_batch_norm'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ae2b24f994e6c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T10:01:43.745999Z",
     "start_time": "2024-04-04T10:01:43.736925Z"
    }
   },
   "outputs": [],
   "source": [
    "# print the training summary\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d098e98e7f8b28ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T10:01:43.911641Z",
     "start_time": "2024-04-04T10:01:43.740446Z"
    }
   },
   "outputs": [],
   "source": [
    "# display the final plot\n",
    "fig = summary.summary_plot\n",
    "# the plot can be saved using savefig\n",
    "# fig.savefig('test_figure')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b91be594c6fc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T10:02:55.724863Z",
     "start_time": "2024-04-04T10:02:55.677451Z"
    }
   },
   "outputs": [],
   "source": [
    "# save model with summary\n",
    "model_path = '../trained_models/example_summary'\n",
    "utils.save_load.save_summary(model_path, summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f80f91e51d9cca3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T10:01:51.456460Z",
     "start_time": "2024-04-04T10:01:43.961630Z"
    }
   },
   "outputs": [],
   "source": [
    "# we can continue training by passing the path to the saved summary to the continue training function \n",
    "additional_epochs = 100\n",
    "retrained_model, new_summary = continue_training(model_path, data_path, additional_epochs)\n",
    "print(new_summary)\n",
    "new_summary.summary_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e121eadc250ad0e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T10:01:58.539824Z",
     "start_time": "2024-04-04T10:01:51.453127Z"
    }
   },
   "outputs": [],
   "source": [
    "# and we can also pass the summary directly, without saving it first\n",
    "retrained_model, new_summary = continue_training(new_summary, data_path, additional_epochs)\n",
    "print(new_summary)\n",
    "new_summary.summary_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19aa6bfe2fc7370",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Second part: Load a trained model and use it to compute assignments.\n",
    "\n",
    "1. load model\n",
    "2. classify\n",
    "```\n",
    "trained_model, _ = utils.save_load.load_model_for_inference(PATH)\n",
    "assignment = classify.classify(trained_model, x, 'one_hot') \n",
    "```\n",
    "classify() works with lists, numpy arrays and torch tensors. Just make sure, the dimensions are correct. The most general input shape is [batch_size, num_kitchens + 1, num_items]. Specify the output format by passing for example 'one_hot' or 'label' to the classify method, see examples below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641fd93a1d9f44c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T10:01:58.674668Z",
     "start_time": "2024-04-04T10:01:58.541139Z"
    }
   },
   "outputs": [],
   "source": [
    "# load trained model to perform inference\n",
    "trained_model, loaded_summary = utils.save_load.load_model_for_inference(model_path)\n",
    "\n",
    "# print training summary\n",
    "print(loaded_summary)\n",
    "\n",
    "# print model architecture\n",
    "print('Model architecture:')\n",
    "print(trained_model)\n",
    "\n",
    "# show training plot\n",
    "loaded_summary.summary_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01d652a6842b9d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T10:01:59.012442Z",
     "start_time": "2024-04-04T10:01:58.676754Z"
    }
   },
   "outputs": [],
   "source": [
    "# load full data from json file and convert to numpy arrays\n",
    "f = open(data_path[0])\n",
    "full_data = json.load(f)\n",
    "food_data = np.array(full_data['food_data_train'])  # [num_examples, num_kitchens + 1, num_items]\n",
    "true_assignments = np.array(full_data['kitchens_data_train'])  # [num_examples, num_kitchens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7babd06c264a17c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T10:01:59.032345Z",
     "start_time": "2024-04-04T10:01:59.014250Z"
    }
   },
   "outputs": [],
   "source": [
    "from classify import classify\n",
    "# classify full dataset and compute accuracy\n",
    "pred = classify(trained_model, food_data, 'label')\n",
    "accuracy = np.sum(np.where(pred - np.argmax(true_assignments, axis=1) == 0, 1, 0)) / len(food_data) * 100\n",
    "print(f'Accuracy over training dataset: {accuracy :.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ba088eb8fce40f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T10:01:59.041628Z",
     "start_time": "2024-04-04T10:01:59.033082Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate a single test example with dimensions [num_kitchens + 1, num_items]\n",
    "num_kitchens = loaded_summary.num_kitchens\n",
    "num_items = loaded_summary.num_food_items\n",
    "\n",
    "# random kitchen inventory\n",
    "means = np.mean(food_data, axis=0)[:num_kitchens, :]\n",
    "stds = np.std(food_data, axis=0)[:num_kitchens, :]\n",
    "random_inventory = stds * np.random.randn(num_kitchens, num_items) + means\n",
    "\n",
    "# one hot item to distribute\n",
    "random_item_to_distribute = np.zeros(num_items)\n",
    "random_item_to_distribute[np.random.choice(num_items)] = 100\n",
    "\n",
    "# combine inventory and item to distribute\n",
    "test_input = np.vstack((random_inventory, random_item_to_distribute))\n",
    "print(f'Shape of test input: {test_input.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfea51de8d3090d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T10:01:59.046170Z",
     "start_time": "2024-04-04T10:01:59.040249Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute assignments with different output encodings\n",
    "assignment_default = classify(trained_model, test_input)\n",
    "print(f'Assignments with probabilities: {assignment_default}')\n",
    "\n",
    "assignment_one_hot = classify(trained_model, test_input, 'one_hot')\n",
    "print(f'Assignments one hot encoded: {assignment_one_hot}')\n",
    "\n",
    "assignment_label = classify(trained_model, test_input, 'label')\n",
    "print(f'Assignments with kitchen labels: {assignment_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d4de95db26676d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T10:01:59.046588Z",
     "start_time": "2024-04-04T10:01:59.043621Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
